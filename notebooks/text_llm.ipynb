{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.cuda.amp import autocast as autocast\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from tnp import TextNeuralPromptModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS = '<s>[INST]'\n",
    "EOS_USER = '[/INST]'\n",
    "EOS = '</s>'\n",
    "IGNORE_INDEX = -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextLLM(torch.nn.Module):\n",
    "    def __init__(self, args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.max_txt_len = args.max_txt_len\n",
    "        self.max_new_tokens = args.max_new_tokens\n",
    "\n",
    "        print('Loading LLAMA')\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(args.llm_model_path, use_fast=False, revision=kwargs[\"revision\"])\n",
    "        self.tokenizer.pad_token_id = 0\n",
    "        self.tokenizer.padding_side = 'left'\n",
    "\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            args.llm_model_path,\n",
    "            torch_dtype=torch.float16,\n",
    "            low_cpu_mem_usage=True,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "        for _, param in model.named_parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.model = model\n",
    "        print('Finish loading LLAMA!')\n",
    "\n",
    "        self.text_encoder = TextNeuralPromptModel(args.lm_model_path)\n",
    "\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(args.gnn_hidden_dim, 2048),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(2048, 4096),\n",
    "        ).to(self.model.device)\n",
    "\n",
    "        self.word_embedding = self.model.model.get_input_embeddings()\n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        return list(self.parameters())[0].device\n",
    "\n",
    "    def maybe_autocast(self, dtype=torch.bfloat16):\n",
    "        # if on cpu, don't use autocast\n",
    "        # if on gpu, use autocast with dtype if provided, otherwise use torch.float16\n",
    "        enable_autocast = self.device != torch.device(\"cpu\")\n",
    "\n",
    "        if enable_autocast:\n",
    "            return torch.cuda.amp.autocast(dtype=dtype)\n",
    "        else:\n",
    "            return contextlib.nullcontext()\n",
    "\n",
    "    def encode_graphs(self, samples):\n",
    "        graphs = samples['graph']\n",
    "        graphs = graphs.to(self.model.device)\n",
    "        embeds = self.text_encoder(graphs)\n",
    "        return embeds\n",
    "\n",
    "    def forward(self, samples):\n",
    "        # encode description, questions and labels\n",
    "        questions = self.tokenizer(samples[\"question\"], add_special_tokens=False)\n",
    "        labels = self.tokenizer(samples[\"label\"], add_special_tokens=False)\n",
    "\n",
    "        # encode special tokens\n",
    "        eos_tokens = self.tokenizer(EOS, add_special_tokens=False)\n",
    "        eos_user_tokens = self.tokenizer(EOS_USER, add_special_tokens=False)\n",
    "        bos_embeds = self.word_embedding(self.tokenizer(BOS, add_special_tokens=False, return_tensors='pt').input_ids[0])\n",
    "        pad_embeds = self.word_embedding(torch.tensor(self.tokenizer.pad_token_id)).unsqueeze(0)\n",
    "\n",
    "        # encode graphs\n",
    "        graph_embeds = self.encode_graphs(samples)\n",
    "        graph_embeds = self.projector(graph_embeds)\n",
    "\n",
    "        batch_size = len(samples['id'])\n",
    "        batch_inputs_embeds = []\n",
    "        batch_attention_mask = []\n",
    "        batch_label_input_ids = []\n",
    "        for i in range(batch_size):\n",
    "            # Add bos & eos token\n",
    "            label_input_ids = labels.input_ids[i][:self.max_new_tokens] + eos_tokens.input_ids\n",
    "            input_ids = questions.input_ids[i] + eos_user_tokens.input_ids + label_input_ids\n",
    "            inputs_embeds = self.word_embedding(torch.tensor(input_ids).to(self.model.device))\n",
    "            inputs_embeds = torch.cat([bos_embeds, graph_embeds[i].unsqueeze(0), inputs_embeds], dim=0)\n",
    "\n",
    "            batch_inputs_embeds.append(inputs_embeds)\n",
    "            batch_attention_mask.append([1] * inputs_embeds.shape[0])\n",
    "            label_input_ids = [IGNORE_INDEX] * (inputs_embeds.shape[0]-len(label_input_ids))+label_input_ids\n",
    "            batch_label_input_ids.append(label_input_ids)\n",
    "\n",
    "        # pad inputs_embeds\n",
    "        max_length = max([x.shape[0] for x in batch_inputs_embeds])\n",
    "        for i in range(batch_size):\n",
    "            pad_length = max_length-batch_inputs_embeds[i].shape[0]\n",
    "            batch_inputs_embeds[i] = torch.cat([pad_embeds.repeat(pad_length, 1), batch_inputs_embeds[i]])\n",
    "            batch_attention_mask[i] = [0]*pad_length+batch_attention_mask[i]\n",
    "            batch_label_input_ids[i] = [IGNORE_INDEX] * pad_length+batch_label_input_ids[i]\n",
    "\n",
    "        inputs_embeds = torch.stack(batch_inputs_embeds, dim=0).to(self.model.device)\n",
    "        attention_mask = torch.tensor(batch_attention_mask).to(self.model.device)\n",
    "        label_input_ids = torch.tensor(batch_label_input_ids).to(self.model.device)\n",
    "\n",
    "        with self.maybe_autocast():\n",
    "            outputs = self.model(\n",
    "                inputs_embeds=inputs_embeds,\n",
    "                attention_mask=attention_mask,\n",
    "                return_dict=True,\n",
    "                labels=label_input_ids,\n",
    "            )\n",
    "\n",
    "        return outputs.loss\n",
    "\n",
    "    def inference(self, samples):\n",
    "\n",
    "        # encode description and questions\n",
    "        questions = self.tokenizer(samples[\"question\"], add_special_tokens=False)\n",
    "\n",
    "        # encode special tokens\n",
    "        eos_user_tokens = self.tokenizer(EOS_USER, add_special_tokens=False)\n",
    "        bos_embeds = self.word_embedding(self.tokenizer(BOS, add_special_tokens=False, return_tensors='pt').input_ids[0])\n",
    "        pad_embeds = self.word_embedding(torch.tensor(self.tokenizer.pad_token_id)).unsqueeze(0)\n",
    "\n",
    "        # encode graphs\n",
    "        graph_embeds = self.encode_graphs(samples)\n",
    "        graph_embeds = self.projector(graph_embeds)\n",
    "\n",
    "        batch_size = len(samples['id'])\n",
    "        batch_inputs_embeds = []\n",
    "        batch_attention_mask = []\n",
    "        for i in range(batch_size):\n",
    "            # Add bos & eos token\n",
    "            input_ids = questions.input_ids[i] + eos_user_tokens.input_ids\n",
    "            inputs_embeds = self.word_embedding(torch.tensor(input_ids).to(self.model.device))\n",
    "            inputs_embeds = torch.cat([bos_embeds, graph_embeds[i].unsqueeze(0), inputs_embeds], dim=0)\n",
    "            batch_inputs_embeds.append(inputs_embeds)\n",
    "            batch_attention_mask.append([1] * inputs_embeds.shape[0])\n",
    "\n",
    "        # pad inputs_embeds\n",
    "        max_length = max([x.shape[0] for x in batch_inputs_embeds])\n",
    "        for i in range(batch_size):\n",
    "            pad_length = max_length-batch_inputs_embeds[i].shape[0]\n",
    "            batch_inputs_embeds[i] = torch.cat([pad_embeds.repeat(pad_length, 1), batch_inputs_embeds[i]])\n",
    "            batch_attention_mask[i] = [0]*pad_length+batch_attention_mask[i]\n",
    "\n",
    "        inputs_embeds = torch.stack(batch_inputs_embeds, dim=0).to(self.model.device)\n",
    "        attention_mask = torch.tensor(batch_attention_mask).to(self.model.device)\n",
    "\n",
    "        with self.maybe_autocast():\n",
    "            outputs = self.model.generate(\n",
    "                inputs_embeds=inputs_embeds,\n",
    "                max_new_tokens=self.max_new_tokens,\n",
    "                attention_mask=attention_mask,\n",
    "                # do_sample=True,\n",
    "                use_cache=True  # IMPORTANT!\n",
    "            )\n",
    "        pred = self.tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "        return {'id': samples['id'],\n",
    "                'pred': pred,\n",
    "                'label': samples['label'],\n",
    "                'question': samples['question'],}\n",
    "\n",
    "    def print_trainable_params(self):\n",
    "        trainable_params = 0\n",
    "        all_param = 0\n",
    "\n",
    "        for _, param in self.named_parameters():\n",
    "            num_params = param.numel()\n",
    "\n",
    "            all_param += num_params\n",
    "            if param.requires_grad:\n",
    "                trainable_params += num_params\n",
    "\n",
    "        return trainable_params, all_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "class SceneGraphDataset(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        super().__init__()\n",
    "        self.path = os.path.join(data_dir, \"sceneGraphs\")\n",
    "        self.path_nodes = f'{self.path}/nodes'\n",
    "        self.path_edges = f'{self.path}/edges'\n",
    "        self.data = pd.read_csv(os.path.join(data_dir, \"questions.csv\"))\n",
    "        self.scene_graphs = self.load_json(os.path.join(self.path, \"scene_graphs_name.json\"))\n",
    "        self.data_list = self.__preprocess__()\n",
    "\n",
    "    def __preprocess__(self):\n",
    "        data_list = []\n",
    "        for idx in tqdm(range(len(self.data))):\n",
    "            data_list.append(\n",
    "                {\n",
    "                    'id':idx,\n",
    "                    'question': self.data.loc[idx]['question'],\n",
    "                    'answer': self.data.loc[idx]['answer'],\n",
    "                    'graph': self.scene_graphs[str(self.data.loc[idx]['image_id'])],\n",
    "                }\n",
    "            )\n",
    "        return data_list\n",
    "\n",
    "    def load_json(self, file_path):\n",
    "        with open(file_path, \"r\") as f:\n",
    "            scene_graphs = json.load(f)\n",
    "        return scene_graphs\n",
    "\n",
    "    def get_idx_split(self):\n",
    "        # Load the saved indices\n",
    "        with open(f'{self.path}/split/train_indices.txt', 'r') as file:\n",
    "            train_indices = [int(line.strip()) for line in file]\n",
    "        with open(f'{self.path}/split/val_indices.txt', 'r') as file:\n",
    "            val_indices = [int(line.strip()) for line in file]\n",
    "        with open(f'{self.path}/split/test_indices.txt', 'r') as file:\n",
    "            test_indices = [int(line.strip()) for line in file]\n",
    "        return {'train': train_indices, 'val': val_indices, 'test': test_indices}\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data_list[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/SSL_NAS/benchmark_data/GQA/'\n",
    "dataset = SceneGraphDataset(data_dir)\n",
    "idx_split = dataset.get_idx_split()\n",
    "train_dataset = [dataset[i] for i in idx_split['train']]\n",
    "val_dataset = [dataset[i] for i in idx_split['val']]\n",
    "test_dataset = [dataset[i] for i in idx_split['test']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

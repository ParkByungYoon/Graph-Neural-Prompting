{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.llm import GraphLLM\n",
    "import torch\n",
    "import os\n",
    "from torch_geometric.loader import DataLoader\n",
    "from src.dataset.obqa import OBQADataset\n",
    "import json\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpnet_dir = '/SSL_NAS/concrete/data/cpnet'\n",
    "with open(os.path.join(cpnet_dir,'concept.txt'), 'r') as f:\n",
    "    cpnet_txt = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda:3'\n",
    "cpnet_dir = '/SSL_NAS/concrete/data/cpnet'\n",
    "text_dir = '/SSL_NAS/concrete/data/obqa/statement'\n",
    "graph_dir = '/SSL_NAS/concrete/data/obqa/graph'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phase = 'test'\n",
    "infer_dataset = OBQADataset(\n",
    "    data_path=os.path.join(text_dir, f'{phase}.jsonl'),\n",
    "    graph_path=os.path.join(graph_dir, f'{phase}.graph.adj.pk-nodenum200.loaded_cache'),\n",
    "    init_emb_path=os.path.join(cpnet_dir, 'tzw.ent.npy'),\n",
    ")\n",
    "infer_loader = DataLoader(infer_dataset, batch_size=1, shuffle=False)\n",
    "len(infer_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose the correct answer from the four options given.\n",
      "Question: Grey clouds can bring\n",
      "Options:\n",
      "(a) sunlight\n",
      "(b) falling water molecules\n",
      "(c) blooming flowers\n",
      "(d) drought conditions\n",
      "Answer:\n",
      "\n",
      "1 broachable\n",
      "1 blue_sky\n",
      "1 coastal_areas_of_alaska\n",
      "1 grey_collar\n",
      "1 grey_clouds\n",
      "1 grey_fog\n",
      "1 sunny_place\n",
      "1 nimbyism\n",
      "1 waterbed_hose\n",
      "1 club\n",
      "1 noctilucin\n",
      "1 gas_form_of_water\n",
      "1 cloudless\n",
      "1 green\n",
      "1 invisibly\n",
      "1 blurry\n",
      "1 deep_copy\n",
      "1 clean_air\n",
      "1 thunder\n",
      "1 climate\n",
      "1 fold\n",
      "1 bills\n",
      "1 sunny\n",
      "1 sun\n",
      "1 bright\n",
      "1 yellow\n",
      "1 black_white\n",
      "1 polyester\n",
      "1 hide_sun\n",
      "1 moving_part\n",
      "1 haze\n",
      "1 bright_sun\n",
      "1 earth\n",
      "1 mars\n",
      "1 lightsome\n",
      "1 goat\n",
      "1 bright_color\n",
      "1 skies_color\n",
      "1 gold_star_mother\n",
      "1 cold_air\n",
      "1 find_inside\n",
      "1 could\n",
      "1 trail\n",
      "1 flugelman\n",
      "2 broachable\n",
      "2 blue_sky\n",
      "2 coastal_areas_of_alaska\n",
      "2 grey_collar\n",
      "2 grey_clouds\n",
      "2 grey_fog\n",
      "2 water_fire\n",
      "2 fall_down\n",
      "2 ladder\n",
      "2 atr\n",
      "2 famil\n",
      "2 bank_account\n",
      "2 water_oak\n",
      "2 water_particles\n",
      "2 waterbed_hose\n",
      "2 cooler\n",
      "2 one_piece_of_medical_equipment\n",
      "2 air_guitaring\n",
      "2 condensed_matter\n",
      "2 slurpee\n",
      "2 surface_normal\n",
      "2 nimbyism\n",
      "2 broken_limbs\n",
      "2 pronounce\n",
      "2 drop_from_tap\n",
      "2 kinds_of_soup\n",
      "2 pyrophosphorolysis\n",
      "2 fructose\n",
      "2 radate\n",
      "2 gravity_kicks_in\n",
      "2 flotation_device\n",
      "2 anhydrite\n",
      "2 whitings\n",
      "2 rainstorm\n",
      "2 use_gravity\n",
      "2 climate\n",
      "2 plume_moth\n",
      "2 less_thirst\n",
      "2 gas_form_of_water\n",
      "2 tripping_and_falling\n",
      "2 cold_air\n",
      "2 onfang\n",
      "2 moisturize\n",
      "2 green\n",
      "2 not_poplar_pieces_of_mail\n",
      "2 deep_copy\n",
      "2 good_exercise\n",
      "2 dousing_chock\n",
      "2 pay_cut\n",
      "2 carbon\n",
      "2 december\n",
      "2 clean_air\n",
      "2 triphenylphosphate\n",
      "2 require_period_of_recuperation\n",
      "2 make_it_up_as_one_goes_along\n",
      "2 thunder\n",
      "2 parallel\n",
      "2 spring\n",
      "2 hydrogen_ion_concentration\n",
      "2 hydrogen_like\n",
      "2 earth\n",
      "2 waterstuff\n",
      "2 beautify\n",
      "2 yellow\n",
      "2 vacuum\n",
      "2 slip_on_kitchen_floor\n",
      "2 catacosmesis\n",
      "2 black_white\n",
      "2 study_of_chemicals\n",
      "2 western_us\n",
      "2 fold\n",
      "2 sun\n",
      "2 cloudwise\n",
      "2 appointive\n",
      "2 blurry\n",
      "2 bright\n",
      "2 polyester\n",
      "2 precipitation_reaction\n",
      "2 trail\n",
      "2 dull\n",
      "2 hot\n",
      "2 dehumidify\n",
      "2 nothing_to_write_home_about\n",
      "2 sunny\n",
      "2 floating\n",
      "2 land\n",
      "2 demangled\n",
      "2 hide_sun\n",
      "2 catch_on\n",
      "2 goat\n",
      "2 lightsome\n",
      "2 hemocyanin\n",
      "2 bills\n",
      "2 everywhere\n",
      "2 trade_deficit\n",
      "2 second\n",
      "2 bright_color\n",
      "2 haze\n",
      "2 assemble\n",
      "2 aphelion\n",
      "2 deliberate\n",
      "2 cautious\n",
      "2 be_happy\n",
      "2 moving_part\n",
      "2 mars\n",
      "2 particle\n",
      "2 bright_sun\n",
      "2 inaction\n",
      "2 algerian_arabic\n",
      "2 backspace\n",
      "2 gold_star_mother\n",
      "2 urban\n",
      "2 minify\n",
      "2 molecule\n",
      "2 inside_box\n",
      "2 issue_pea\n",
      "2 come_back\n",
      "2 residency\n",
      "2 living_human\n",
      "2 psychological\n",
      "2 bathochromic\n",
      "2 individual\n",
      "2 cement_lawn_gnomes_and_pink_flamingos\n",
      "2 cause_bone_fractures\n",
      "2 belong_to_set\n",
      "2 rim\n",
      "2 avision\n",
      "2 tent\n",
      "2 wooden\n",
      "2 pangram\n",
      "2 ferry\n",
      "2 eve\n",
      "2 dropping_confetti\n",
      "2 prosuicide\n",
      "2 descend_mountain\n",
      "2 falling_anvil\n",
      "2 happenstance\n",
      "2 accidental_drowning\n",
      "2 death\n",
      "2 takeoff\n",
      "2 aon\n",
      "2 steepled\n",
      "2 calm_slowly\n",
      "2 flugelman\n",
      "2 could\n",
      "2 use_walker\n",
      "2 condensation\n",
      "2 making_up\n",
      "2 find_inside\n",
      "2 friction\n",
      "2 mineral_vegetable\n",
      "2 founder\n",
      "2 give_back\n",
      "2 emerge\n",
      "2 getting_good_at\n",
      "2 shoe_boxes\n",
      "2 destroyable\n",
      "2 molecules\n",
      "2 empty_space\n",
      "2 meta_analysis\n",
      "2 tunnel\n",
      "2 christian_band\n",
      "2 skillful\n",
      "2 oxidase\n",
      "3 broachable\n",
      "3 blue_sky\n",
      "3 coastal_areas_of_alaska\n",
      "3 grey_collar\n",
      "3 grey_clouds\n",
      "3 grey_fog\n",
      "3 blouse\n",
      "3 moving\n",
      "3 front_yard\n",
      "3 bouquet_of_flowers\n",
      "3 blooming_heck\n",
      "3 gorgeous\n",
      "3 nimbyism\n",
      "3 waterbed_hose\n",
      "3 fetid\n",
      "3 bifocal\n",
      "3 efflower\n",
      "3 opens\n",
      "3 burst_into_tears\n",
      "3 greengrocer\n",
      "3 aflush\n",
      "3 petal_stool\n",
      "3 manufactured\n",
      "3 bouquet_of_circles\n",
      "3 flower_arrangement\n",
      "3 efflorescence\n",
      "3 red_on\n",
      "3 delight_person\n",
      "3 nectarinid\n",
      "3 flowerpot\n",
      "3 female_reproductive_part_of_flower\n",
      "3 bloomerism\n",
      "3 black_carp\n",
      "3 thorny_stems\n",
      "3 taker\n",
      "3 intensified\n",
      "3 gas_form_of_water\n",
      "3 apir_of_shoes\n",
      "3 flowery_blossom\n",
      "3 green\n",
      "3 flowering\n",
      "3 parking\n",
      "3 catacosmesis\n",
      "3 deep_copy\n",
      "3 polyester\n",
      "3 reblossom\n",
      "3 climate\n",
      "3 mars\n",
      "3 goat\n",
      "3 blurry\n",
      "3 bright\n",
      "3 leaflet\n",
      "3 vegetable\n",
      "3 sun\n",
      "3 clean_air\n",
      "3 black_white\n",
      "3 sunny\n",
      "3 parked\n",
      "3 bills\n",
      "3 pie\n",
      "3 plants\n",
      "3 antiblue\n",
      "3 hide_sun\n",
      "3 earth\n",
      "3 prewar\n",
      "3 fold\n",
      "3 bright_color\n",
      "3 bright_sun\n",
      "3 moving_part\n",
      "3 yellow\n",
      "3 gold_star_mother\n",
      "3 pink_cigar\n",
      "3 haze\n",
      "3 pen\n",
      "3 pollux\n",
      "3 die_from_pollution\n",
      "3 gets_bigger\n",
      "3 devil\n",
      "3 thunder\n",
      "3 find_underground\n",
      "3 yellow_vegetable\n",
      "3 cold_air\n",
      "3 swim\n",
      "3 address\n",
      "3 profitable\n",
      "3 trunk\n",
      "3 grayscale\n",
      "3 trail\n",
      "3 could\n",
      "3 lightsome\n",
      "3 flugelman\n",
      "3 bloomy\n",
      "3 urban\n",
      "3 get_broken\n",
      "3 solid\n",
      "3 find_inside\n",
      "3 bunch_of_fives\n",
      "3 non_generic\n",
      "3 implement\n",
      "3 garden_or_florist_shop\n",
      "4 broachable\n",
      "4 blue_sky\n",
      "4 coastal_areas_of_alaska\n",
      "4 grey_collar\n",
      "4 grey_clouds\n",
      "4 grey_fog\n",
      "4 shampoo\n",
      "4 flooded\n",
      "4 funny_when_broken\n",
      "4 nimbyism\n",
      "4 waterbed_hose\n",
      "4 ground_level\n",
      "4 break_with\n",
      "4 wh_question\n",
      "4 climate\n",
      "4 green\n",
      "4 bigger_threat_than_global_terrorism\n",
      "4 gas_form_of_water\n",
      "4 pay_cut\n",
      "4 bright\n",
      "4 fold\n",
      "4 deep_copy\n",
      "4 polyester\n",
      "4 news_sports\n",
      "4 black_white\n",
      "4 sun\n",
      "4 sometimes_never\n",
      "4 clean_air\n",
      "4 yellow\n",
      "4 bills\n",
      "4 goat\n",
      "4 precipitation_reaction\n",
      "4 blurry\n",
      "4 earth\n",
      "4 bright_sun\n",
      "4 atomic_numbers\n",
      "4 bright_color\n",
      "4 dim\n",
      "4 hide_sun\n",
      "4 thunder\n",
      "4 gold_star_mother\n",
      "4 beautify\n",
      "4 lightsome\n",
      "4 haze\n",
      "4 increase\n",
      "4 mars\n",
      "4 formless\n",
      "4 cold_air\n",
      "4 dropout\n",
      "4 commonly\n",
      "4 trail\n",
      "4 could\n",
      "4 put_together\n",
      "4 find_inside\n",
      "4 area_look\n",
      "4 moving_part\n",
      "4 transmitter\n",
      "4 flugelman\n",
      "4 profit\n"
     ]
    }
   ],
   "source": [
    "question_id = 100\n",
    "print(infer_dataset[question_id]['question'])\n",
    "for idx, concept_id in enumerate(infer_dataset[question_id]['graphs'].concept_ids):\n",
    "    if concept_id.item() in [0,1]:\n",
    "        continue\n",
    "    print((idx//200)+1,cpnet_txt[concept_id][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args: pass\n",
    "args = Args()\n",
    "args.max_txt_len = 512\n",
    "args.max_new_tokens = 32\n",
    "args.llm_model_path = \"google/flan-t5-xl\"\n",
    "args.llm_frozen = True\n",
    "args.cache_dir = \"/SSL_NAS/peoples/bonbak/model\"\n",
    "args.learning_rate = 1e-4\n",
    "args.input_dim = 1024\n",
    "args.hidden_dim = 1024\n",
    "args.seed = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "012a3e3352ec4bdd9f5da4ba154f6977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(args.llm_model_path, cache_dir = args.cache_dir).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(args.llm_model_path, cache_dir = args.cache_dir)\n",
    "word_embedding = model.get_input_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd39684104484c188ff2ebf5b96879bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "prediction = []\n",
    "ground_truth = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for samples in tqdm(infer_loader, total=len(infer_loader)):\n",
    "        questions = tokenizer(samples['question'], add_special_tokens=False)\n",
    "        inputs_embeds = word_embedding(torch.tensor(questions.input_ids).to(device))\n",
    "\n",
    "        attention_mask = torch.tensor(questions.attention_mask).unsqueeze(dim=0).to(device)\n",
    "        outputs = model.generate(\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            max_new_tokens=args.max_new_tokens,\n",
    "            attention_mask=attention_mask,\n",
    "        )\n",
    "        pred = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "        gt = samples['answer']\n",
    "\n",
    "        prediction.append(pred[0])\n",
    "        ground_truth.append(gt[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.734"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_match = 0\n",
    "for pred, gt in zip(prediction, ground_truth):\n",
    "    p = pred.replace('(','').replace(')','')[0].lower()\n",
    "    a = gt.replace('(','').replace(')','')[0].lower()\n",
    "    if p == a:\n",
    "        num_match += 1\n",
    "num_match / len(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GraphToken",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
